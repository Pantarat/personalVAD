{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Personal VAD architecture evaluation\n",
    "This notebook serves as a tool for model evaluation. Contrary to the evaluate_models.py script, this notebook \n",
    "can help evaluate each model individually.\n",
    "\n",
    "The notebook NEEDS access to the `data/eval_dir/` directory to work correctly -- simply run the notebook inside the `src/`\n",
    "directory to ensure this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import kaldiio\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_sequence\n",
    "from sklearn.metrics import average_precision_score, confusion_matrix, accuracy_score, ConfusionMatrixDisplay\n",
    "\n",
    "from personal_vad import PersonalVAD, pad_collate\n",
    "from vad import VadDataset\n",
    "from vad_et import VadETDataset\n",
    "from vad_set import VadSETDataset\n",
    "from vad_st import VadSTDataset\n",
    "from vad_xvector import VadETDatasetX\n",
    "from vad_ivector import VadETDatasetI\n",
    "from evaluate_models import parse_model_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AP, mAP, confusion matrix, accuracy personal VAD evaluation\n",
    "Before proceeding, select the evaluated model name, and if necessary, specify the name of your evaluation dataset. The\n",
    "evaluated model HAS to reside in the ``data/eval_dir/models/`` directory, the data folder HAS to reside in ``data/eval_dir/data/``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move to the evaluation directory.. if this is causing you problems, just\n",
    "# set the eval_dir variable to the absolute path of 'data/eval_dir' on your system...\n",
    "eval_dir = '../data/eval_dir'\n",
    "print(os.getcwd())\n",
    "os.chdir(eval_dir)\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set these up to your liking...\n",
    "model = 'vad_et_10ep_linear_ivec_l2.pt'\n",
    "eval_set = 'data/test'\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Here are some model names to try out... for a full list, please take a look into the data/eval_dir/models directory.\n",
    "\n",
    "vad_et_10ep_linear.pt\n",
    "vad_et_10ep_tanh_wpl_0.5.pt\n",
    "vad_set_tanh_score1_10ep.pt\n",
    "vad_st_tanh_score2_8ep.pt\n",
    "vad_et_10ep_xvec_l2.pt\n",
    "vad_et_10ep_linear_ivec_l2.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the model information\n",
    "ret = parse_model_name(model)\n",
    "if ret == None: print(\"Invalid or unsupported model name supplied..\")\n",
    "(arch, embed, use_fc, linear, score_type, input_dim) = ret\n",
    "\n",
    "model_path = 'models/' + model\n",
    "\n",
    "\n",
    "# load the model, prepare the datset and data loader...\n",
    "net = PersonalVAD(input_dim=input_dim, hidden_dim=64, num_layers=2,\n",
    "        out_dim=3, use_fc=use_fc, linear=linear)\n",
    "net.load_state_dict(torch.load(model_path))\n",
    "\n",
    "# create the corresponding dataset objects with the correct\n",
    "# target speaker embedding directory selected\n",
    "if arch == 'et':\n",
    "    if embed == 'dvec':\n",
    "        test_data = VadETDataset(eval_set, 'embeddings')\n",
    "    elif embed == 'xvec':\n",
    "        test_data = VadETDatasetX(eval_set, 'embeddings_xvec_l2')\n",
    "\n",
    "    else: # ivec\n",
    "        if 'l2' in model:\n",
    "            test_data = VadETDatasetI(eval_set, 'embeddings_ivec_l2')\n",
    "        else:\n",
    "            test_data = VadETDatasetI(eval_set, 'embeddings_ivec')\n",
    "\n",
    "elif arch == 'set':\n",
    "    test_data = VadSETDataset(eval_set, 'embeddings', score_type)\n",
    "\n",
    "elif arch == 'st':\n",
    "    test_data = VadSTDataset(eval_set, score_type)\n",
    "\n",
    "else:\n",
    "    # we should not get here\n",
    "    print(\"We actually got here -__-\")\n",
    "\n",
    "# setup the data loader\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=batch_size,\n",
    "        num_workers=2, shuffle=False, collate_fn=pad_collate)\n",
    "\n",
    "# set the device to cuda and move the model to the gpu\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "net = net.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mAP evaluation\n",
    "softmax = torch.nn.Softmax(dim=1)\n",
    "targets = []\n",
    "outputs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    for x_padded, y_padded, x_lens, y_lens in test_loader:\n",
    "        y_padded = y_padded.to(device)\n",
    "\n",
    "        # pass the data through the model\n",
    "        out_padded, _ = net(x_padded.to(device), x_lens, None)\n",
    "\n",
    "        # value, index\n",
    "        for j in range(out_padded.size(0)):\n",
    "            p = softmax(out_padded[j][:y_lens[j]])\n",
    "            outputs.append(p.cpu().numpy())\n",
    "            targets.append(y_padded[j][:y_lens[j]].cpu().numpy())\n",
    "                \n",
    "targets = np.concatenate(targets)\n",
    "outputs = np.concatenate(outputs)\n",
    "print(targets.shape)\n",
    "print(outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the target array to one hot\n",
    "targets_oh = np.eye(3)[targets]\n",
    "\n",
    "# and run the AP\n",
    "out_AP = average_precision_score(targets_oh, outputs, average=None)\n",
    "mAP = average_precision_score(targets_oh, outputs, average='micro')\n",
    "\n",
    "# print the average precision scores for all classes as well as the micro-averaged mean average precision score\n",
    "print(model)\n",
    "print('  ns   |   ntss   |   tss') \n",
    "print(out_AP) \n",
    "print(f\"mAP: {mAP}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute and plot the model confusion matrix\n",
    "classes = np.argmax(outputs, axis=1)\n",
    "cm = confusion_matrix(classes, targets, normalize='pred')\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,  display_labels=['ns', 'ntss', 'tss'])\n",
    "disp.plot()\n",
    "\n",
    "# compute model classification accuracy\n",
    "acc = accuracy_score(classes, targets)\n",
    "print(model)\n",
    "print(\"accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline VAD evaluation\n",
    "This part of the notebook can be used for the evaluation of the baseline speech/non-speech VAD system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure we are in the correct directory..\n",
    "eval_dir = '../data/eval_dir'\n",
    "print(os.getcwd())\n",
    "os.chdir(eval_dir)\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set these up to your liking, as above..\n",
    "model = 'vad_tanh_6ep.pt'\n",
    "model_path = 'models/' + model\n",
    "eval_data = 'data/test'\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = False if 'tanh' in model else False\n",
    "\n",
    "# load the model and setup the dataset object\n",
    "net = PersonalVAD(input_dim=40, hidden_dim=64, num_layers=2, out_dim=2, linear=linear)\n",
    "net.load_state_dict(torch.load(model_path))\n",
    "test_data = VadDataset(eval_data)\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "net = net.to(device)\n",
    "\n",
    "test_loader = DataLoader(\n",
    "        dataset=test_data, batch_size=batch_size, num_workers=2, shuffle=False, collate_fn=pad_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mAP evaluation\n",
    "softmax = torch.nn.Softmax(dim=1)\n",
    "targets = []\n",
    "outputs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x_padded, y_padded, x_lens, y_lens in test_loader:\n",
    "        y_padded = y_padded.to(device)\n",
    "\n",
    "        # pass the data through the model\n",
    "        out_padded, _ = net(x_padded.to(device), x_lens, None)\n",
    "\n",
    "        # value, index\n",
    "        for j in range(out_padded.size(0)):\n",
    "            p = out_padded[j][:y_lens[j]]\n",
    "            \n",
    "            outputs.append(p.cpu().numpy())\n",
    "            targets.append(y_padded[j][:y_lens[j]].cpu().numpy())\n",
    "                \n",
    "targets = np.concatenate(targets)\n",
    "outputs = np.concatenate(outputs)\n",
    "print(targets.shape)\n",
    "print(outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the target array to one hot\n",
    "targets_oh = np.eye(2)[targets.astype(int)]\n",
    "outputs_oh = np.hstack((1 - outputs, outputs))\n",
    "\n",
    "# and compute the AP scores\n",
    "out_AP = average_precision_score(targets_oh, outputs, average=None)\n",
    "mAP = average_precision_score(targets_oh, outputs, average='micro')\n",
    "\n",
    "print(model)\n",
    "print('  speech   |   non-speech') \n",
    "print(out_AP) \n",
    "print(f\"mAP: {mAP}\")\n",
    "print(\"accuracy:\", accuracy_score(targets, np.argmax(outputs, axis=1)))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# baseline VAD evaluation results...\n",
    "\n",
    "VAD linear clean\n",
    "[0.949  0.998]\n",
    "mAP: 0.995\n",
    "accuracy: 96.48\n",
    "\n",
    "VAD linear aug\n",
    "[0.915 0.996]\n",
    "mAP: 0.991\n",
    "accuracy: 94.93\n",
    "\n",
    "VAD tanh clean\n",
    "[0.947 0.998]\n",
    "mAP: 0.995\n",
    "accuracy: 96.34\n",
    "\n",
    "VAD tanh aug\n",
    "[0.913 0.996]\n",
    "mAP: 0.990\n",
    "accuracy: 94.85"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline SC system\n",
    "This part of the notebook can be used for the baseline SC system evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure we are in the correct directory..\n",
    "eval_dir = '../data/eval_dir'\n",
    "print(os.getcwd())\n",
    "os.chdir(eval_dir)\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set these up to your liking, as above..\n",
    "model = 'vad_linear_6ep.pt'\n",
    "model_path = 'models/' + model\n",
    "eval_data = 'data/test'\n",
    "score_type = 0\n",
    "batch_size = 64\n",
    "\n",
    "# set the EER threshold value depending on the d-vector extraction method for the SC modification\n",
    "EER_threshold = 0.5329 if score_type == 0 else 0.5822"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaselineDataset(Dataset):\n",
    "    \"\"\"VadSC training dataset class. Uses kaldi scp and ark files.\n",
    "    \n",
    "    This dataset class had to be created explicitly for the SC architecture, as there\n",
    "    are some specifics none of the other dataset classes really cover.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, root_dir, score_type):\n",
    "        self.root_dir = root_dir\n",
    "        self.score_type = score_type\n",
    "\n",
    "        self.fbanks = kaldiio.load_scp(f'{self.root_dir}/fbanks.scp')\n",
    "        self.scores = kaldiio.load_scp(f'{self.root_dir}/scores.scp')\n",
    "        self.labels = kaldiio.load_scp(f'{self.root_dir}/labels.scp')\n",
    "        self.keys = np.array(list(self.fbanks)) # get all the keys\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.keys.size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        key = self.keys[idx]\n",
    "        x = self.fbanks[key]\n",
    "        scores = self.scores[key][self.score_type,:]\n",
    "        y = self.labels[key]\n",
    "\n",
    "        x = torch.from_numpy(x).float()\n",
    "        scores = torch.from_numpy(scores).float()\n",
    "        y = torch.from_numpy(y).long()\n",
    "        return x, scores, y\n",
    "\n",
    "def baseline_pad_collate(batch):\n",
    "    \"\"\"Padding function used to deal with batches of sequences of variable lengths for\n",
    "    the baseline SC PVAD system.\n",
    "    \n",
    "    The scores are not padded and have to be returned as separate tensors, not\n",
    "    as parts of the input features.\n",
    "    \"\"\"\n",
    "\n",
    "    (xx, scores, yy) = zip(*batch)\n",
    "    x_lens = [len(x) for x in xx]\n",
    "    y_lens = [len(y) for y in yy]\n",
    "    x_padded = pad_sequence(xx, batch_first=True, padding_value=0)\n",
    "    y_padded = pad_sequence(yy, batch_first=True, padding_value=0)\n",
    "    return x_padded, y_padded, scores, x_lens, y_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = False if 'tanh' in model else True\n",
    "\n",
    "# load the model, setup the dataset object\n",
    "net = PersonalVAD(input_dim=40, hidden_dim=64, num_layers=2, out_dim=2, linear=linear)\n",
    "net.load_state_dict(torch.load(model_path))\n",
    "test_data = BaselineDataset(eval_data, score_type)\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "net = net.to(device)\n",
    "\n",
    "# create the dataloader object\n",
    "test_loader = DataLoader(\n",
    "        dataset=test_data, batch_size=batch_size, num_workers=2, shuffle=False, collate_fn=baseline_pad_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mAP evaluation\n",
    "softmax = torch.nn.Softmax(dim=1)\n",
    "targets = []\n",
    "outputs = []\n",
    "is_tss = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x_padded, y_padded, scores, x_lens, y_lens in test_loader:\n",
    "        # pass the data through the model\n",
    "        out_padded, _ = net(x_padded.to(device), x_lens, None)\n",
    "\n",
    "        # value, index\n",
    "        for j in range(out_padded.size(0)):\n",
    "            score = scores[j]\n",
    "            x = out_padded[j][:y_lens[j]].cpu()\n",
    "            x = softmax(x)\n",
    "            \n",
    "            # now combine the scores with the vad probability to obtain class probabilities\n",
    "            ns = x[:,0]\n",
    "            ntss = x[:,1] * (1 - score)\n",
    "            tss = x[:,1] * score\n",
    "            \n",
    "            # baseline modification - produces 1D predicted class index array\n",
    "            # this is a bit of a mess, just bare with me..\n",
    "            x2 = x.numpy()\n",
    "            score2 = score.numpy()\n",
    "            b = (x2[:,0] < x2[:,1]).astype('int') # 0 if ns, 1 if speech\n",
    "            c = (score2 > EER_threshold).astype('int') # 0 if ntss, 1 if tss\n",
    "            d = ((b == c) & (b != 0)).astype('int') * 2 #  2 if tss, 0 else\n",
    "            e = np.where((c == 0) & (b != 0), 1, 0)\n",
    "            is_tss.append(d + e)\n",
    "            \n",
    "            out = torch.stack((ns, ntss, tss)).T\n",
    "            out = softmax(out)\n",
    "            \n",
    "            outputs.append(out.numpy())\n",
    "            targets.append(y_padded[j][:y_lens[j]].numpy())\n",
    "                \n",
    "targets = np.concatenate(targets)\n",
    "outputs = np.concatenate(outputs)\n",
    "is_tss = np.concatenate(is_tss)\n",
    "print(targets.shape)\n",
    "print(outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the target array to one hot\n",
    "targets_oh = np.eye(3)[targets]\n",
    "\n",
    "# and run the AP\n",
    "out_AP = average_precision_score(targets_oh, outputs, average=None)\n",
    "mAP = average_precision_score(targets_oh, outputs, average='micro')\n",
    "\n",
    "print(model)\n",
    "print(out_AP) \n",
    "print(f\"mAP: {mAP}\")\n",
    "print(\"accuracy:\", accuracy_score(targets, np.argmax(outputs, axis=1)))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# baseline SC system results (linear VAD variant)\n",
    "clean\n",
    "[0.948 0.846 0.864]\n",
    "mAP: 0.825\n",
    "accuracy: 73.44\n",
    "\n",
    "aug\n",
    "[0.915 0.775 0.811]\n",
    "mAP: 0.796\n",
    "accuracy: 72.09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the accuracy of the SC EER threshold modification\n",
    "print(model)\n",
    "print(\"accuracy:\", accuracy_score(targets, is_tss))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
